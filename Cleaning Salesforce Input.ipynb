{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Salesforce Input\n",
    "This project cleans a spreadsheet for a client to upload a long list of vendors into Salesforce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spreadsheet has separate worksheets for every state. We want to load each worksheet into its own dataframe for easy concatenation. Start by initilizing an empty dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AL': 0, 'AK': 0, 'AZ': 0, 'AR': 0, 'CA': 0, 'CO': 0, 'CT': 0, 'DE': 0, 'FL': 0, 'GA': 0, 'HI': 0, 'ID': 0, 'IL': 0, 'IN': 0, 'IA': 0, 'KS': 0, 'KY': 0, 'LA': 0, 'ME': 0, 'MD': 0, 'MA': 0, 'MI': 0, 'MN': 0, 'MS': 0, 'MO': 0, 'MT': 0, 'NE': 0, 'NV': 0, 'NH': 0, 'NJ': 0, 'NM': 0, 'NY': 0, 'NC': 0, 'ND': 0, 'OH': 0, 'OK': 0, 'OR': 0, 'PA': 0, 'RI': 0, 'SC': 0, 'SD': 0, 'TN': 0, 'TX': 0, 'UT': 0, 'VT': 0, 'VA': 0, 'WA': 0, 'WV': 0, 'WI': 0, 'WY': 0}\n"
     ]
    }
   ],
   "source": [
    "# Load a csv with state abbreviations\n",
    "states_df = pd.read_csv('C:\\\\Users\\\\avery\\\\OneDrive\\\\TBTN\\\\state_abbreviations.csv')\n",
    "\n",
    "# Select just the abbreviations \n",
    "states_series = states_df['code']\n",
    "\n",
    "# Initilize a dictionary from the series\n",
    "raw_df_dict = dict.fromkeys(states_series, 0)\n",
    "\n",
    "print(raw_df_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to load one worksheet given an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_states(state):\n",
    "    \n",
    "    # Specify file path\n",
    "    file_path = 'C:\\\\Users\\\\avery\\\\OneDrive\\\\TBTN\\\\manual_studio_spreadsheet.xlsx'\n",
    "    \n",
    "    # Load Excel worksheet with state name\n",
    "    temp_df = pd.read_excel(file_path, sheet_name=state)\n",
    "    \n",
    "    # Store in dictionary as value for state key\n",
    "    raw_df_dict[state] = temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over the dictionary, loading each worksheet into the appropriate value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['STATUS', 'Studio Name', 'Address', 'Address Line 2', 'City', 'State',\n",
      "       'Zip', 'Phone number', 'Unnamed: 8', 'Email', 'Website',\n",
      "       'Owner First Name', 'Owner Last Name', 'Past Participant (Y/N)',\n",
      "       'Years of Participation', 'WHO CONTACTED & EMAIL', 'DATE CONTACTED',\n",
      "       'FOLLOW UP DATE', 'YES/MAYBE/NO', 'Signed Agreement?', '$ Raised',\n",
      "       'NOTES', 'Salesforce', 'Salesforce Status'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "for key in raw_df_dict:\n",
    "    load_states(key)\n",
    "\n",
    "print(raw_df_dict['OH'].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate all dataframes together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3556, 61)\n"
     ]
    }
   ],
   "source": [
    "combined_df = pd.concat(raw_df_dict, axis=0, ignore_index=True, copy=False)\n",
    "\n",
    "print(combined_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know we have too many columns. Some we may need to adjust manually. Let's export a dataframe that contains the columns and the number of values in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "export = pd.DataFrame(combined_df.count(), columns=['counts'])\n",
    "\n",
    "export['fixed_status'] = False\n",
    "\n",
    "export.to_csv('C:\\\\Users\\\\avery\\\\OneDrive\\\\TBTN\\\\columns_check.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our column counts and a view into the data with Excel, we can perform a series of cleaning steps.\n",
    "\n",
    "### Drop unneeded columns\n",
    "\n",
    "First, drop all columns we know we don't need: either they have no values, incoherent values, or the client has expressed they don't care about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['STATUS', 'Studio Name', 'Address', 'City', 'State', 'Zip',\n",
      "       'Phone number', 'Email', 'Website', 'Owner First Name',\n",
      "       'Owner Last Name', 'Past Participant Notes', 'Years of Participation',\n",
      "       'NOTES', 'Salesforce', 'Salesforce Status', 'Address Line 2',\n",
      "       'Past Participant (Y/N)', ' ', 'Unnamed: 8', 'NOTES.1',\n",
      "       'Sent Free Webinar Email', 'Group/ Business Name ', 'City/ Village ',\n",
      "       'Zipcode ', 'Phone Number ', 'Email for Website ',\n",
      "       'Social Media Account', 'Temporarily closed Covet 19', 'Notes ',\n",
      "       'Free Webinar Email', 'Salesforce ', 'Salesforce Status ',\n",
      "       'Free Webinar email', 'Zip (they all have 0 in front)',\n",
      "       'In Salesforce?', 'f', 'Free Webinar', 'STATUS - Amy's Marketing',\n",
      "       'Marketing Email'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "drop_list = ['Saleforce Status', \n",
    "            'Unnamed: 13', \n",
    "            'Unnamed: 14', \n",
    "            'Unnamed: 18', \n",
    "            'Unnamed: 19', \n",
    "            'Unnamed: 20',\n",
    "            'Unnamed: 21',\n",
    "            'Unnamed: 24',\n",
    "            'Salesforce Notes',\n",
    "            '$ Raised',\n",
    "            'Signed Agreement?',\n",
    "            'Unnamed: 0',\n",
    "            'Follow-Up Date ',\n",
    "            'Date Contacted',\n",
    "            'YES/MAYBE/NO',\n",
    "            'FOLLOW UP DATE',\n",
    "            'DATE CONTACTED',\n",
    "            'WHO CONTACTED & EMAIL',\n",
    "            'Who ContACTED & EMAIL',\n",
    "            'Status for Studio Outreach',\n",
    "            '2nd Follow Up date']\n",
    "\n",
    "counts_only_df = combined_df.drop(drop_list, axis=1)\n",
    "\n",
    "print(counts_only_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are several categories that have multiple columns. We should combine them into one column per category.\n",
    "\n",
    "Let's define a function to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate(df, source_columns, target_column):\n",
    "    \n",
    "    # Print the original column count\n",
    "    origin_count = df[source_columns].count()\n",
    "    print('Original: ' + str(origin_count))\n",
    "    target_count = df[target_column].count()\n",
    "    print('Target: ' + str(target_count))\n",
    "    \n",
    "    # Transform column list into a series so it can be used to fill na\n",
    "    column_series = df[source_columns]\n",
    "    \n",
    "    # Fill na values from other lists, storing in new df\n",
    "    result_df = df\n",
    "    \n",
    "    result_df[target_column] = df[target_column].fillna(column_series)\n",
    "    \n",
    "    # Print output column counts\n",
    "    source_count = result_df[source_columns].count()\n",
    "    result_count = result_df[target_column].count()\n",
    "    \n",
    "    # Print results\n",
    "    print('Source: ' + str(source_count))\n",
    "    print('Result: ' + str(result_count))\n",
    "    \n",
    "    # Return new df\n",
    "    return result_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "consolidate(counts_only_df, 'In Salesforce?', 'Salesforce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidate Repeated Columns\n",
    "\n",
    "Call `consolidate()` on each category we need to combine. We should do this with a list or dictionary and a loop, but the function isn't working with that method, so let's just save troubleshooting time and do it manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 2\n",
      "Target: 158\n",
      "Source: 2\n",
      "Result: 160\n"
     ]
    }
   ],
   "source": [
    "sales_fix_1 = consolidate(counts_only_df, 'In Salesforce?', 'Salesforce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 7\n",
      "Target: 160\n",
      "Source: 7\n",
      "Result: 167\n"
     ]
    }
   ],
   "source": [
    "sales_fix_2 = consolidate(sales_fix_1, 'Salesforce ', 'Salesforce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 8\n",
      "Target: 157\n",
      "Source: 8\n",
      "Result: 165\n"
     ]
    }
   ],
   "source": [
    "status_fix_1 = consolidate(sales_fix_2, 'Salesforce Status ', 'Salesforce Status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 71\n",
      "Target: 3364\n",
      "Source: 71\n",
      "Result: 3435\n"
     ]
    }
   ],
   "source": [
    "city_fix = consolidate(status_fix_1, 'City/ Village ', 'City')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 71\n",
      "Target: 2743\n",
      "Source: 71\n",
      "Result: 2814\n"
     ]
    }
   ],
   "source": [
    "zip_fix_1 = consolidate(city_fix, 'Zipcode ', 'Zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 41\n",
      "Target: 2814\n",
      "Source: 41\n",
      "Result: 2855\n"
     ]
    }
   ],
   "source": [
    "zip_fix_2 = consolidate(zip_fix_1, 'Zip (they all have 0 in front)', 'Zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like this fix isn't working. Let's make a note to work this out manually and then move on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 65\n",
      "Target: 830\n",
      "Source: 65\n",
      "Result: 895\n"
     ]
    }
   ],
   "source": [
    "notes_fix_1 = consolidate(zip_fix_2, 'Notes ', 'NOTES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 5\n",
      "Target: 895\n",
      "Source: 5\n",
      "Result: 900\n"
     ]
    }
   ],
   "source": [
    "notes_fix_2 = consolidate(notes_fix_1, 'Past Participant Notes', 'NOTES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 67\n",
      "Target: 900\n",
      "Source: 67\n",
      "Result: 935\n"
     ]
    }
   ],
   "source": [
    "notes_fix_3 = consolidate(notes_fix_2, 'f', 'NOTES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 43\n",
      "Target: 935\n",
      "Source: 43\n",
      "Result: 976\n"
     ]
    }
   ],
   "source": [
    "notes_fix_4 = consolidate(notes_fix_3, 'Unnamed: 8', 'NOTES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 10\n",
      "Target: 20\n",
      "Source: 10\n",
      "Result: 30\n"
     ]
    }
   ],
   "source": [
    "webinar_fix_1 = consolidate(notes_fix_4, 'Sent Free Webinar Email', 'Free Webinar Email')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 11\n",
      "Target: 30\n",
      "Source: 11\n",
      "Result: 41\n"
     ]
    }
   ],
   "source": [
    "webinar_fix_2 = consolidate(webinar_fix_1, 'Free Webinar', 'Free Webinar Email')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 17\n",
      "Target: 41\n",
      "Source: 17\n",
      "Result: 58\n"
     ]
    }
   ],
   "source": [
    "webinar_fix_3 = consolidate(webinar_fix_2, 'Free Webinar email', 'Free Webinar Email')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 42\n",
      "Target: 3292\n",
      "Source: 42\n",
      "Result: 3334\n"
     ]
    }
   ],
   "source": [
    "phone_fix_1 = consolidate(webinar_fix_3, ' ', 'Phone number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 70\n",
      "Target: 3334\n",
      "Source: 70\n",
      "Result: 3404\n"
     ]
    }
   ],
   "source": [
    "phone_fix_2 = consolidate(phone_fix_1, 'Phone Number ', 'Phone number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 71\n",
      "Target: 3462\n",
      "Source: 71\n",
      "Result: 3533\n"
     ]
    }
   ],
   "source": [
    "studio_fix_1 = consolidate(phone_fix_2, 'Group/ Business Name ', 'Studio Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 54\n",
      "Target: 976\n",
      "Source: 54\n",
      "Result: 978\n"
     ]
    }
   ],
   "source": [
    "notes_fix_5 = consolidate(studio_fix_1, 'NOTES.1', 'NOTES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 29\n",
      "Target: 2843\n",
      "Source: 29\n",
      "Result: 2872\n"
     ]
    }
   ],
   "source": [
    "email_fix = consolidate(notes_fix_5, 'Email for Website ', 'Email') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we're finished moving values, let's drop the above columns from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3556, 40)\n",
      "(3556, 19)\n"
     ]
    }
   ],
   "source": [
    "drop_second_list = ['In Salesforce?',\n",
    "                    'Salesforce ', \n",
    "                    'Salesforce Status ', \n",
    "                    'City/ Village ', \n",
    "                    'Zipcode ', \n",
    "                    'Notes ',\n",
    "                    'Past Participant Notes',\n",
    "                    'f',\n",
    "                    'Unnamed: 8',\n",
    "                    'Sent Free Webinar Email',\n",
    "                    'Free Webinar',\n",
    "                    'Free Webinar email',\n",
    "                    'Phone Number ',\n",
    "                    'Group/ Business Name ',\n",
    "                    'NOTES.1',\n",
    "                    'Email for Website ', \n",
    "                    'Zip (they all have 0 in front)',\n",
    "                    \"STATUS - Amy's Marketing\", \n",
    "                    'Marketing Email', \n",
    "                    'Free Webinar Email',\n",
    "                    ' '\n",
    "                   ]\n",
    "\n",
    "good_col_df = email_fix.drop(drop_second_list, axis=1)\n",
    "\n",
    "print(notes_fix_5.shape)\n",
    "print(good_col_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['STATUS', 'Studio Name', 'Address', 'City', 'State', 'Zip',\n",
       "       'Phone number', 'Email', 'Website', 'Owner First Name',\n",
       "       'Owner Last Name', 'Years of Participation', 'NOTES', 'Salesforce',\n",
       "       'Salesforce Status', 'Address Line 2', 'Past Participant (Y/N)',\n",
       "       'Social Media Account', 'Temporarily closed Covet 19'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_col_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Address Lines\n",
    "\n",
    "Because Salesforce only accepts one address field, the client asked to have the two address fields combined. Let's do that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['STATUS', 'Studio Name', 'Address', 'City', 'State', 'Zip',\n",
      "       'Phone number', 'Email', 'Website', 'Owner First Name',\n",
      "       'Owner Last Name', 'Years of Participation', 'NOTES', 'Salesforce',\n",
      "       'Salesforce Status', 'Past Participant (Y/N)', 'Social Media Account',\n",
      "       'Temporarily closed Covet 19'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "address_fix = good_col_df\n",
    "\n",
    "# Concatenate strings\n",
    "address_fix['Address'] = address_fix['Address'].astype(str) + ' ' + address_fix['Address Line 2'].astype(str)\n",
    "\n",
    "# drop second column\n",
    "address_fix.drop('Address Line 2', axis=1, inplace=True)\n",
    "\n",
    "print(address_fix.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strip trailing commas, spaces, and Nan from addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_fix['Address'] = address_fix['Address'].str.rstrip('Nan')\n",
    "address_fix['Address'] = address_fix['Address'].str.rstrip()\n",
    "address_fix['Address'] = address_fix['Address'].str.rstrip(',')\n",
    "address_fix['Address'] = address_fix['Address'].str.rstrip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove titles \n",
    "During the concatenation process some column titles got put in with the data. Remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATUS                         2\n",
      "Studio Name                    2\n",
      "Address                        2\n",
      "City                           2\n",
      "State                          2\n",
      "Zip                            2\n",
      "Phone number                   2\n",
      "Email                          2\n",
      "Website                        2\n",
      "Owner First Name               2\n",
      "Owner Last Name                2\n",
      "Years of Participation         2\n",
      "NOTES                          2\n",
      "Salesforce                     0\n",
      "Salesforce Status              0\n",
      "Past Participant (Y/N)         2\n",
      "Social Media Account           0\n",
      "Temporarily closed Covet 19    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "title_condition = address_fix['State'] == 'State'\n",
    "\n",
    "initial_count = address_fix.loc[title_condition, :].count()\n",
    "\n",
    "print(initial_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATUS                         0\n",
      "Studio Name                    0\n",
      "Address                        0\n",
      "City                           0\n",
      "State                          0\n",
      "Zip                            0\n",
      "Phone number                   0\n",
      "Email                          0\n",
      "Website                        0\n",
      "Owner First Name               0\n",
      "Owner Last Name                0\n",
      "Years of Participation         0\n",
      "NOTES                          0\n",
      "Salesforce                     0\n",
      "Salesforce Status              0\n",
      "Past Participant (Y/N)         0\n",
      "Social Media Account           0\n",
      "Temporarily closed Covet 19    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "title_fix = address_fix.loc[~title_condition, :]\n",
    "\n",
    "after_count = title_fix.loc[title_condition, :].count()\n",
    "\n",
    "print(after_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    3529\n",
       "True       25\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_fix.duplicated(['Studio Name', 'Address', 'Website']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    3529\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "unique_fix = title_fix.drop_duplicates(subset=['Studio Name', 'Address', 'Website'])\n",
    "\n",
    "print(unique_fix.duplicated(['Studio Name', 'Address', 'Website']).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_fix.to_csv('C:\\\\Users\\\\avery\\\\OneDrive\\\\TBTN\\\\merged_check.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix Phone Numbers\n",
    "\n",
    "Took this cool function from sackoverflow. https://stackoverflow.com/a/62219947/14456176"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsephone(strphone):\n",
    "    '''\n",
    "    Pull out just the digits. Then do some simple formating.\n",
    "    '''\n",
    "    phn = \"\"\n",
    "    for n in strphone:\n",
    "        if n in \"0123456789\":\n",
    "            phn += n\n",
    "    if len(phn) == 10:  # add a 1 in front\n",
    "        phn = \"1\" + phn\n",
    "    if len(phn) != 11 or len(phn) <=6:\n",
    "        return phn  # no hope of formating\n",
    "    # format with dashes\n",
    "    phn = \"(\" + phn[1:4] + \") \" + phn[4:7] + \"-\" + phn[7:]\n",
    "    return phn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       (334) 787-2110\n",
      "1       (251) 639-9030\n",
      "2       (205) 540-5842\n",
      "3       (205) 202-5758\n",
      "4       (256) 405-9226\n",
      "             ...      \n",
      "3551    (307) 752-2858\n",
      "3552    (307) 358-9888\n",
      "3553    (307) 413-0441\n",
      "3554    (208) 317-0994\n",
      "3555      307.680.7762\n",
      "Name: Phone number, Length: 3529, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(unique_fix.loc[:, 'Phone number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avery\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1048: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n"
     ]
    }
   ],
   "source": [
    "phone_format = unique_fix\n",
    "phone_format.loc[:, 'Phone number'] = phone_format.loc[:, 'Phone number'].astype('str')\n",
    "\n",
    "phone_format.loc[:, 'Phone number'] = phone_format.loc[:, 'Phone number'].apply(lambda x: parsephone(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       (334) 787-2110\n",
      "1       (251) 639-9030\n",
      "2       (205) 540-5842\n",
      "3       (205) 202-5758\n",
      "4       (256) 405-9226\n",
      "             ...      \n",
      "3551    (307) 752-2858\n",
      "3552    (307) 358-9888\n",
      "3553    (307) 413-0441\n",
      "3554    (208) 317-0994\n",
      "3555    (307) 680-7762\n",
      "Name: Phone number, Length: 3529, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(phone_format.loc[:, 'Phone number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "phone_format.to_csv('C:\\\\Users\\\\avery\\\\OneDrive\\\\TBTN\\\\phone_check.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove totally blank rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATUS                         2290\n",
      "Studio Name                       3\n",
      "Address                           0\n",
      "City                            101\n",
      "State                            29\n",
      "Zip                             676\n",
      "Phone number                      0\n",
      "Email                           661\n",
      "Website                         908\n",
      "Owner First Name               2501\n",
      "Owner Last Name                2870\n",
      "Years of Participation         3464\n",
      "NOTES                          2554\n",
      "Salesforce                     3362\n",
      "Salesforce Status              3364\n",
      "Past Participant (Y/N)         3445\n",
      "Social Media Account           3460\n",
      "Temporarily closed Covet 19    3460\n",
      "dtype: int64\n",
      "STATUS                         2288\n",
      "Studio Name                       0\n",
      "Address                           0\n",
      "City                            100\n",
      "State                            28\n",
      "Zip                             675\n",
      "Phone number                      0\n",
      "Email                           659\n",
      "Website                         907\n",
      "Owner First Name               2498\n",
      "Owner Last Name                2867\n",
      "Years of Participation         3461\n",
      "NOTES                          2551\n",
      "Salesforce                     3359\n",
      "Salesforce Status              3361\n",
      "Past Participant (Y/N)         3442\n",
      "Social Media Account           3457\n",
      "Temporarily closed Covet 19    3457\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(phone_format.isna().sum())\n",
    "\n",
    "no_blanks = phone_format.dropna(subset=['Studio Name'])\n",
    "\n",
    "print(no_blanks.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['STATUS', 'Studio Name', 'Address', 'City', 'State', 'Zip',\n",
      "       'Phone number', 'Email', 'Website', 'Owner First Name',\n",
      "       'Owner Last Name', 'Years of Participation', 'NOTES', 'Salesforce',\n",
      "       'Salesforce Status', 'Past Participant (Y/N)', 'Social Media Account',\n",
      "       'Temporarily closed Covet 19'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(no_blanks.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Status', 'Studio Name', 'Address', 'City', 'State', 'Zip', 'Phone',\n",
      "       'Email', 'Website', 'Owner First Name', 'Owner Last Name',\n",
      "       'Years of Participation', 'Notes', 'Salesforce Uploaded',\n",
      "       'Salesforce Type', 'Past Participant', 'Social Media Account',\n",
      "       'Temporary COVID Closure'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "new_names_dict = {'STATUS': 'Status',\n",
    "                  'Phone number': 'Phone', \n",
    "                  'NOTES': 'Notes', \n",
    "                  'Salesforce':'Salesforce Uploaded',\n",
    "                  'Salesforce Status':'Salesforce Type',\n",
    "                  'Temporarily closed Covet 19':'Temporary COVID Closure', \n",
    "                  'Past Participant (Y/N)': 'Past Participant'\n",
    "                  }\n",
    "\n",
    "renamed = no_blanks.rename(new_names_dict, axis=1)\n",
    "\n",
    "print(renamed.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capitalize Vendor Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                            7Synergy\n",
      "1    Above And Beyond Hot Yoga Center\n",
      "2                      Abundance Yoga\n",
      "3                            Aero Joe\n",
      "4                Back In Balance Yoga\n",
      "Name: Studio Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "capitalized = renamed\n",
    "\n",
    "capitalized['Studio Name'] = renamed['Studio Name'].str.title()\n",
    "\n",
    "capitalized['Address'] = renamed['Address'].str.title()\n",
    "\n",
    "print(capitalized['Studio Name'].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restructure Vendor Names \n",
    "The client requests that vendor names that start with \"the\" be transformed to \"(The)\". We'll copy the trick from the `parsephone()` function above and reconfigure it to fit this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brace_the(origin_str):\n",
    "    \"\"\" Reformats a string if it contains \"The\"\n",
    "    \"\"\"\n",
    "    if origin_str[0:3] == 'The':\n",
    "        result_str = '(' + origin_str[0:3] + ')' + origin_str[3:]\n",
    "    else:\n",
    "        result_str = origin_str\n",
    "    \n",
    "    return result_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                            7Synergy\n",
      "1    Above And Beyond Hot Yoga Center\n",
      "2                      Abundance Yoga\n",
      "3                            Aero Joe\n",
      "4                Back In Balance Yoga\n",
      "Name: Studio Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "braced_df = capitalized\n",
    "\n",
    "braced_df.loc[:, 'Studio Name'] = braced_df.loc[:, 'Studio Name'].apply(lambda x: brace_the(x))\n",
    "\n",
    "print(braced_df['Studio Name'].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "braced_df.to_csv('C:\\\\Users\\\\avery\\\\OneDrive\\\\TBTN\\\\brace_check.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enforce response consistency\n",
    "The data was entered manually by many different people, and so we want to ensure we have uniform data in the final version. For example, we will want to turn Booleans from \"yes\", \"not yet\" or \"YES!!!\" into True or False.\n",
    "\n",
    "These are the important columns to enforce:\n",
    "\n",
    "* Status\n",
    "* Years of Participation \n",
    "* Salesforce Uploaded\n",
    "* Salesforce Type\n",
    "* Past Participant\n",
    "* Social Media Account\n",
    "* Temporary COVID Closure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emailed                                          286\n",
      "contacted                                         81\n",
      "contacted & FP                                    43\n",
      "Done                                              42\n",
      "REPEAT                                            39\n",
      "                                                ... \n",
      "d                                                  1\n",
      "mailbox not set up                                 1\n",
      "DOne                                               1\n",
      "Email/Phone                                        1\n",
      "sent email+phone number has been disconnected      1\n",
      "Name: Status, Length: 292, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(braced_df['Status'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, it looks like `Status` is nowhere close to a Boolean. Instead, it's more like a notes column. Let's leave this alone for now. When we're talking with the client on how to enforce data consistency going forward, let's see what they want this column to look like. We'll suggest a Boolean and leave notes for the `Notes` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      54\n",
      "-       6\n",
      "1.0     5\n",
      "Name: Years of Participation, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(braced_df['Years of Participation'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Years of Participation` looks much simpler. Change '-' and nulls to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3521\n",
       "1       5\n",
       "Name: Years of Participation, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create conditions to find all '-' and nulls\n",
    "years_hyphen_condition = braced_df['Years of Participation'] == '-'\n",
    "years_null_condition = braced_df['Years of Participation'].isna()\n",
    "\n",
    "# Locate all '-' and null values and set to '0'\n",
    "braced_df.loc[years_hyphen_condition, 'Years of Participation'] = 0\n",
    "braced_df.loc[years_null_condition, 'Years of Participation'] = 0\n",
    "\n",
    "# Change datatype to int\n",
    "braced_df['Years of Participation'] = braced_df['Years of Participation'].astype('int')\n",
    "\n",
    "# Check output\n",
    "braced_df['Years of Participation'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the column `Salesforce Uploaded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes                    86\n",
      "2020-10-25 00:00:00    16\n",
      "2020-08-18 00:00:00    12\n",
      "2020-07-31 00:00:00     7\n",
      "yes                     4\n",
      "2020-08-01 00:00:00     4\n",
      "2020-09-16 00:00:00     3\n",
      "2020-06-29 00:00:00     3\n",
      "2020-08-23 00:00:00     3\n",
      "2020-06-24 00:00:00     2\n",
      "2020-07-03 00:00:00     2\n",
      "2020-08-17 00:00:00     2\n",
      "2020-07-26 00:00:00     2\n",
      "YES                     2\n",
      "2020-07-23 00:00:00     2\n",
      "2020-09-15 00:00:00     1\n",
      "2020-08-07 00:00:00     1\n",
      "YES                     1\n",
      "2020-07-01 00:00:00     1\n",
      "2020-07-30 00:00:00     1\n",
      "2020-09-14 00:00:00     1\n",
      "2020-11-04 00:00:00     1\n",
      "2020-07-21 00:00:00     1\n",
      "2020-07-19 00:00:00     1\n",
      "2020-09-18 00:00:00     1\n",
      "2020-08-29 00:00:00     1\n",
      "2020-06-26 00:00:00     1\n",
      "2020-07-28 00:00:00     1\n",
      "2020-07-08 00:00:00     1\n",
      "2020-09-12 00:00:00     1\n",
      "2020-08-12 00:00:00     1\n",
      "2020-09-17 00:00:00     1\n",
      "Name: Salesforce Uploaded, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(braced_df['Salesforce Uploaded'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The timestamp of upload isn't important there. Change all non-null values to 'Yes' and all nulls to 'No'. (Normally we'd set this to True or False, but our client will probably feel more comfortable with 'Yes' or 'No'.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No     3359\n",
      "Yes     167\n",
      "Name: Salesforce Uploaded, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create conditions\n",
    "salesforce_not_null = braced_df['Salesforce Uploaded'].notnull()\n",
    "salesforce_null = braced_df['Salesforce Uploaded'].isna()\n",
    "\n",
    "# Set values to 'Yes' or 'No'\n",
    "braced_df.loc[salesforce_not_null, 'Salesforce Uploaded'] = 'Yes'\n",
    "braced_df.loc[salesforce_null, 'Salesforce Uploaded'] = 'No'\n",
    "\n",
    "# Check output\n",
    "print(braced_df['Salesforce Uploaded'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check `Salesforce Type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "account       87\n",
      "Account       55\n",
      "F Account     12\n",
      "F Account      4\n",
      "Account        3\n",
      "ACCOUNT        3\n",
      "account        1\n",
      "Name: Salesforce Type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(braced_df['Salesforce Type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3361\n"
     ]
    }
   ],
   "source": [
    "print(braced_df['Salesforce Type'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears there are two real distinct categories, Account and F Account. There are many options for how to make this happen. Since there are several types of errors but only a few total, let's use a dictionary approach to replace the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Account      149\n",
      "F Account     16\n",
      "Name: Salesforce Type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "account_dict = {'account': 'Account', \n",
    "                'Account ': 'Account', \n",
    "                'ACCOUNT': 'Account', \n",
    "                'account ': 'Account', \n",
    "                'F Account ': 'F Account'}\n",
    "\n",
    "braced_df['Salesforce Type'].replace(account_dict, inplace=True)\n",
    "\n",
    "print(braced_df['Salesforce Type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check `Past Participant`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N                                                                                                               63\n",
      "Y                                                                                                                4\n",
      "YES                                                                                                              3\n",
      "Che                                                                                                              2\n",
      "No                                                                                                               1\n",
      "general manager                                                                                                  1\n",
      "Yes                                                                                                              1\n",
      "left message; Left message 8/26, owner Roseann picked up phone, is interested. Sent her email with info 8/26     1\n",
      "Jennings                                                                                                         1\n",
      "Almost then dropped                                                                                              1\n",
      "Sent email 8/26                                                                                                  1\n",
      "Duyn                                                                                                             1\n",
      "left message, will call me back; Left message and sent email 8/26                                                1\n",
      "founder/ studio director                                                                                         1\n",
      "JEFF PERCACCIANTE                                                                                                1\n",
      "Hargrove                                                                                                         1\n",
      "Name: Past Participant, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(braced_df['Past Participant'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like it should be Boolean. It's also labeled `'Past Participant (Y/N)'` originally, so it's safe to assume they want it to be Boolean. Again, because our client will be more comfortable with it, let's convert all these values into 'Yes' or 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No     3507\n",
      "Yes      19\n",
      "Name: Past Participant, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "par_fix = braced_df\n",
    "\n",
    "# Create condition for 'No' values\n",
    "no_participant_list = ['Almost then dropped', 'N']\n",
    "no_participant_condition = (braced_df['Past Participant'].isin(no_participant_list)) | (braced_df['Past Participant'].isna())\n",
    "\n",
    "# Locate nos and set to 'No'\n",
    "par_fix.loc[no_participant_condition, 'Past Participant'] = 'No'\n",
    "\n",
    "# Create condition for 'Yes'\n",
    "yes_participant_condition = braced_df['Past Participant'] != 'No'\n",
    "\n",
    "# Locate yes values and set to 'Yes'\n",
    "par_fix.loc[yes_participant_condition, 'Past Participant'] = 'Yes'\n",
    "\n",
    "# Check output\n",
    "print(par_fix['Past Participant'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check `Social Media Account`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facebook                       61\n",
      "Facebook                        3\n",
      "Unable to Find Social Media     2\n",
      "FaceBook                        2\n",
      "No Social Media Found           1\n",
      "Name: Social Media Account, dtype: int64\n",
      "3457\n"
     ]
    }
   ],
   "source": [
    "print(par_fix['Social Media Account'].value_counts())\n",
    "\n",
    "print(par_fix['Social Media Account'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert all to either 'Facebook' or null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facebook    66\n",
      "Name: Social Media Account, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "social_fix = par_fix\n",
    "\n",
    "social_map = {'Facebook ': 'Facebook', \n",
    "              'FaceBook ': 'Facebook', \n",
    "              'Unable to Find Social Media': np.nan, \n",
    "              'No Social Media Found ': np.nan}\n",
    "\n",
    "social_fix.loc[:, 'Social Media Account'].replace(social_map, inplace=True)\n",
    "\n",
    "print(social_fix['Social Media Account'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, check `Temporary COVID Closure`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open              41\n",
      "Closed            20\n",
      "Open               7\n",
      "Online Classes     1\n",
      "Name: Temporary COVID Closure, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(social_fix['Temporary COVID Closure'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be Boolean, but let's stick to the terms that the client used. We could set a default value, but let's not add useless data unnecessarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open       49\n",
      "Closed     20\n",
      "Name: Temporary COVID Closure, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "closure_fix = social_fix\n",
    "\n",
    "closure_map = {'Open ': 'Open', \n",
    "              'Online Classes': 'Open'}\n",
    "\n",
    "closure_fix.loc[:, 'Temporary COVID Closure'].replace(closure_map, inplace=True)\n",
    "\n",
    "print(closure_fix['Temporary COVID Closure'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the dataframe with unified values to see if other steps should be taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "closure_fix.to_csv('C:\\\\Users\\\\avery\\\\OneDrive\\\\TBTN\\\\enforced_check.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformat nulls in Address\n",
    "Convert 'Nan' in `Address` to 'None'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_clean = closure_fix\n",
    "\n",
    "address_clean.loc[:, 'Address'] = closure_fix.loc[:, 'Address'].replace({'Nan':'None'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enforce correct states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MA     493\n",
      "WA     248\n",
      "OR     196\n",
      "CA     151\n",
      "NV     105\n",
      "FL     103\n",
      "IL      78\n",
      "NY      77\n",
      "TX      75\n",
      "AL      75\n",
      "OH      69\n",
      "MN      67\n",
      "NY      66\n",
      "NM      65\n",
      "KY      62\n",
      "CT      61\n",
      "CO      61\n",
      "MT      60\n",
      "TN      59\n",
      "MS      59\n",
      "PA      55\n",
      "IA      55\n",
      "MD      53\n",
      "NC      52\n",
      "AZ      51\n",
      "NH      50\n",
      "MO      49\n",
      "NE      49\n",
      "SC      48\n",
      "NJ      48\n",
      "LA      47\n",
      "UT      45\n",
      "GA      45\n",
      "RI      43\n",
      "WI      42\n",
      "ME      42\n",
      "VT      42\n",
      "AR      41\n",
      "MI      38\n",
      "IN      37\n",
      "WY      36\n",
      "WV      35\n",
      "ID      35\n",
      "AK      34\n",
      "OK      32\n",
      "ND      30\n",
      "VA      27\n",
      "HI      26\n",
      "DE      24\n",
      "SD      24\n",
      "KS      23\n",
      "MN       4\n",
      "NV       2\n",
      "UT       1\n",
      "VY       1\n",
      "WY       1\n",
      "FL       1\n",
      "Name: State, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "correct_states = address_clean\n",
    "\n",
    "correct_state_map = {'Iowa':'IA', \n",
    "                     'Alabama': 'AL', \n",
    "                     'Kansas': 'KS', \n",
    "                     'Kankas ': 'KS', \n",
    "                     'Kansas ': 'KS'}\n",
    "\n",
    "correct_states['State'] = correct_states['State'].replace(correct_state_map)\n",
    "\n",
    "correct_states['State'] = correct_states['State'].str.upper()\n",
    "\n",
    "print(correct_states['State'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Switch incorrect email/website fields\n",
    "When reviewing the data output, I noticed that some states had their website and email fields switched. Let's make sure the right values are in the right column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Email  \\\n",
      "2377         caryflowyoga@gmail.com   \n",
      "2378      INFO@PURAVIDASTUDIONC.COM   \n",
      "2379        info@republicofyoga.com   \n",
      "2380        jennie@wisemindyoga.com   \n",
      "2381                            NaN   \n",
      "2382                            NaN   \n",
      "2383         info@zenyogacenter.com   \n",
      "2384           info@CaryHotYoga.com   \n",
      "2385           info@bluelotusnc.com   \n",
      "2386        info@blissbody-yoga.com   \n",
      "2387          info@yogagardennc.com   \n",
      "2388      info@yourbodymechanic.com   \n",
      "2389   hotyogartpcarymorr@gmail.com   \n",
      "2390            winter@barre-up.com   \n",
      "2391    frank@ignitefitnessapex.com   \n",
      "2392                            NaN   \n",
      "2393                            NaN   \n",
      "2394                            NaN   \n",
      "2395            110YOGANC@GMAIL.COM   \n",
      "2396                            NaN   \n",
      "2397    info@midtownyogastudios.com   \n",
      "2398    smilingcircleyoga@gmail.com   \n",
      "2399       brighttreeyoga@gmail.com   \n",
      "2400          cyndi@zaktihealth.com   \n",
      "2401                            NaN   \n",
      "2402                            NaN   \n",
      "2403    yobastudioraleigh@gmail.com   \n",
      "2404                            NaN   \n",
      "2405         raleigh@bodynbrain.com   \n",
      "2406      Straussmadeline@gmail.com   \n",
      "2407   info@yogainspiredraleigh.com   \n",
      "2408                            NaN   \n",
      "2409                            NaN   \n",
      "2410                            NaN   \n",
      "2411                            NaN   \n",
      "2412                            NaN   \n",
      "2413         info@carolinabarre.com   \n",
      "2414                            NaN   \n",
      "2415  tiffany@yogainthetriangle.com   \n",
      "2416  COLORSOFYOGARALEIGH@GMAIL.COM   \n",
      "2417                            NaN   \n",
      "2418            info@AYSraleigh.com   \n",
      "2419             info@arrichion.com   \n",
      "2420                            NaN   \n",
      "2421                            NaN   \n",
      "2422                            NaN   \n",
      "2423                            NaN   \n",
      "2424          bodi4wisdom@gmail.com   \n",
      "2425           openartsnc@gmail.com   \n",
      "2426                            NaN   \n",
      "2427           info@bluelotusnc.com   \n",
      "2428              info@youryoga.com   \n",
      "\n",
      "                                                Website  \n",
      "2377                   http://caryflowyoga.com/contact/  \n",
      "2378      https://www.puravidastudionc.com/new-page-47/  \n",
      "2379                             www.republicofyoga.com  \n",
      "2380               https://wisemindyoga.com/contact-us/  \n",
      "2381           https://www.corepoweryoga.com/contact-us  \n",
      "2382                     https://yoga-mojo.com/contact/  \n",
      "2383           https://www.zenyogacenter.com/contact-us  \n",
      "2384                 http://www.caryhotyoga.com/contact  \n",
      "2385                       https://www.bluelotusnc.com/  \n",
      "2386                        https://blissbody-yoga.com/  \n",
      "2387                       http://www.yogagardennc.com/  \n",
      "2388              https://yourbodymechanic.com/contact/  \n",
      "2389                https://www.hotyogartpcarymorr.com/  \n",
      "2390             https://www.barreupraleigh.com/contact  \n",
      "2391             https://ignitefitnessapex.com/contact/  \n",
      "2392                     http://www.evolvemovement.com/  \n",
      "2393                 http://zinyogawine.com/contact-us/  \n",
      "2394                                                NaN  \n",
      "2395                                http://110yoga.com/  \n",
      "2396                    https://www.elementhotyoga.org/  \n",
      "2397  https://midtownyogastudios.com/location-and-co...  \n",
      "2398              http://smilingcircleyoga.com/contact/  \n",
      "2399                https://brighttreeyoga.com/contact/  \n",
      "2400           https://www.zaktihealth.com/contact.html  \n",
      "2401                                                NaN  \n",
      "2402          https://www.discoveryogapt.com/contact-us  \n",
      "2403                  http://www.yobastudio.com/contact  \n",
      "2404         https://hotasanastudio.com/about-hot-asana  \n",
      "2405                 https://www.bodynbrain.com/raleigh  \n",
      "2406                      https://myyoganc.com/contact/  \n",
      "2407    https://yogainspiredraleigh.com/connect-with-us  \n",
      "2408                https://www.opendooryogastudio.com/  \n",
      "2409           https://www.corepoweryoga.com/contact-us  \n",
      "2410   http://www.integralyogastudio.com/contact_us.php  \n",
      "2411                          https://maryonthemat.com/  \n",
      "2412                https://barre3.com/studio-locations  \n",
      "2413              https://carolinabarre.com/contact-us/  \n",
      "2414                https://movewellphilly.com/contact/  \n",
      "2415              http://yogainthetriangle.com/contact/  \n",
      "2416        https://www.colorsofyogaraleigh.com/contact  \n",
      "2417                         https://raleighncyoga.com/  \n",
      "2418                https://www.aysraleigh.com/#contact  \n",
      "2419                      https://arrichion.com/connect  \n",
      "2420                    https://raleighyogacompany.com/  \n",
      "2421                                http://yogaclub.us/  \n",
      "2422                https://wythabalance.com/contactus/  \n",
      "2423                         https://cattiltstudio.com/  \n",
      "2424                        https://www.bodiwisdom.com/  \n",
      "2425                  http://openartsnc.com/contact-us/  \n",
      "2426                                                NaN  \n",
      "2427                        http://www.bluelotusnc.com/  \n",
      "2428     https://www.youryoga.com/ayc-donation-request/  \n"
     ]
    }
   ],
   "source": [
    "# Initialize new df\n",
    "switched_df = pd.DataFrame(correct_states, copy=True)\n",
    "\n",
    "# List the states with wrong fields\n",
    "states_to_switch = ['NC', 'NM', 'NE', 'MT']\n",
    "\n",
    "# Create general switch condition\n",
    "switch_condition = switched_df['State'].isin(states_to_switch) & (switched_df['Email'].str.contains('@', regex=False) == False)\n",
    "\n",
    "# PA just has a couple to switch. \n",
    "# Let's swap all website values that contain '@'.\n",
    "# Create PA condition\n",
    "pa_switch_condition = (switched_df['State'] == 'PA') & (switched_df['Website'].str.contains('@', regex=False) == True)\n",
    "\n",
    "# Initialize source columns to pull from\n",
    "switched_df['source_email'] = switched_df['Email']\n",
    "switched_df['source_website'] = switched_df['Website']\n",
    "\n",
    "# For all incorrect states, set 'Email' to 'source_website' and 'Website' to 'Source Email'\n",
    "switched_df.loc[switch_condition, 'Email'] = switched_df.loc[switch_condition, 'source_website']\n",
    "switched_df.loc[switch_condition, 'Website'] = switched_df.loc[switch_condition, 'source_email']\n",
    "\n",
    "# Repeat with PA\n",
    "switched_df.loc[pa_switch_condition, 'Email'] = switched_df.loc[pa_switch_condition, 'source_website']\n",
    "switched_df.loc[pa_switch_condition, 'Website'] = switched_df.loc[pa_switch_condition, 'source_email']\n",
    "\n",
    "# Drop source columns\n",
    "switch_complete_df = switched_df.drop(['source_email', 'source_website'], axis=1)\n",
    "\n",
    "# Check output\n",
    "print(switch_complete_df.loc[switch_complete_df['State'] == 'NC', ['Email', 'Website']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enforce emails only in 'Email' column\n",
    "\n",
    "For the `Email` column, replace any value that has no '@' symbol with null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    3153\n",
      "True      373\n",
      "Name: Email, dtype: int64\n",
      "709\n",
      "1082\n"
     ]
    }
   ],
   "source": [
    "# Initialize new df\n",
    "email_enforce = switch_complete_df\n",
    "\n",
    "# Create condition\n",
    "not_an_email = email_enforce['Email'].str.contains('@', regex=False) == False\n",
    "\n",
    "# Check that condition works\n",
    "print(not_an_email.value_counts())\n",
    "print(email_enforce['Email'].isna().sum())\n",
    "\n",
    "# Set values that don't meet the condition to null\n",
    "email_enforce.loc[not_an_email, 'Email'] = np.nan\n",
    "\n",
    "# Check output\n",
    "print(email_enforce['Email'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polish City and Email string format\n",
    "Fix capitalization on `'City'` and `'Email'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize new df\n",
    "capital_polish_df = email_enforce\n",
    "\n",
    "# Fix City\n",
    "capital_polish_df['City'] = capital_polish_df['City'].str.title()\n",
    "\n",
    "# Strip trailing commas and spaces\n",
    "capital_polish_df['City'] = capital_polish_df['City'].str.lstrip()\n",
    "capital_polish_df['City'] = capital_polish_df['City'].str.rstrip(',')\n",
    "capital_polish_df['City'] = capital_polish_df['City'].str.rstrip()\n",
    "capital_polish_df['City'] = capital_polish_df['City'].str.rstrip(',')\n",
    "capital_polish_df['City'] = capital_polish_df['City'].str.rstrip()\n",
    "\n",
    "capital_polish_df['Email'] = capital_polish_df['Email'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create logical column order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Status', 'Studio Name', 'Address', 'City', 'State', 'Zip', 'Phone',\n",
       "       'Email', 'Website', 'Owner First Name', 'Owner Last Name',\n",
       "       'Years of Participation', 'Notes', 'Salesforce Uploaded',\n",
       "       'Salesforce Type', 'Past Participant', 'Social Media Account',\n",
       "       'Temporary COVID Closure'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capital_polish_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df = capital_polish_df[['Studio Name', \n",
    "                               'Address', \n",
    "                               'City', \n",
    "                               'State', \n",
    "                               'Zip', \n",
    "                               'Phone',\n",
    "                               'Email', \n",
    "                               'Website', \n",
    "                               'Owner First Name', \n",
    "                               'Owner Last Name', \n",
    "                               'Social Media Account', \n",
    "                               'Past Participant',\n",
    "                               'Years of Participation', \n",
    "                               'Status', \n",
    "                               'Notes', \n",
    "                               'Temporary COVID Closure', \n",
    "                               'Salesforce Uploaded',\n",
    "                               'Salesforce Type',\n",
    "                              ]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df.to_csv('C:\\\\Users\\\\avery\\\\OneDrive\\\\TBTN\\\\clean_master_export.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done!\n",
    "The dataset is now relatively tidy and ready for the client."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisions\n",
    "After reviewing the product, the client made some clarifications and requests. I also caught some more issues I want to fix before calling it complete.\n",
    "\n",
    "First, drop `'Salesforce Type'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = pd.DataFrame(export_df, copy=True)\n",
    "\n",
    "review_df.drop('Salesforce Type', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename `'Status'` to indicate that it holds past data, then add a new column `'Contact Attempts'` to represent the data we want to collect in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Studio Name', 'Address', 'City', 'State', 'Zip', 'Phone', 'Email',\n",
      "       'Website', 'Owner First Name', 'Owner Last Name',\n",
      "       'Social Media Account', 'Past Participant', 'Years of Participation',\n",
      "       'status_notes_2020', 'Notes', 'Temporary COVID Closure',\n",
      "       'Salesforce Uploaded', 'Contact Attempts'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "status_fix = review_df.rename({'Status':'status_notes_2020'}, axis=1)\n",
    "\n",
    "status_fix['Contact Attempts'] = np.nan\n",
    "\n",
    "print(status_fix.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix a few capitalizations. Make 'Ymca' and 'Llc' all caps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "caps_fix = status_fix\n",
    "\n",
    "print(caps_fix['Studio Name'].str.contains('ymca', case=False).sum())\n",
    "\n",
    "caps_condition = caps_fix['Studio Name'].str.contains('ymca', case=False)\n",
    "\n",
    "caps_fix.loc[caps_condition, 'Studio Name'] = caps_fix['Studio Name'].str.replace('Ymca','YMCA', case=True)\n",
    "\n",
    "print(caps_fix['Studio Name'].str.contains('Ymca', case=True).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "llc_fix = pd.DataFrame(caps_fix, copy=True)\n",
    "\n",
    "print(llc_fix['Studio Name'].str.contains('llc', case=False).sum())\n",
    "\n",
    "llc_condition = llc_fix['Studio Name'].str.contains('llc', case=False)\n",
    "\n",
    "llc_fix.loc[llc_condition, 'Studio Name'] = llc_fix['Studio Name'].str.replace('Llc','LLC', case=True)\n",
    "\n",
    "print(llc_fix['Studio Name'].str.contains('Llc', case=True).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ready for final export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "llc_fix.to_csv('C:\\\\Users\\\\avery\\\\OneDrive\\\\TBTN\\\\clean_master_revised.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
